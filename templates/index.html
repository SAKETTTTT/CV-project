<!DOCTYPE html>
<html>
<head>
    <title>Emotion Recognition</title>
    <style>
        body { 
            font-family: sans-serif; 
            text-align: center; 
            background-color: #f0f0f0; 
            padding: 20px;
        }
        h1 { 
            color: #333; 
        }
        #video-container {
            display: flex;
            flex-direction: column;
            align-items: center;
            margin-top: 20px;
        }
        video { 
            border: 2px solid #555; 
            border-radius: 8px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            margin-bottom: 20px;
        }
        #captureBtn {
            padding: 10px 20px;
            font-size: 16px;
            cursor: pointer;
            border-radius: 5px;
            border: none;
            background-color: #007bff;
            color: white;
        }
        #result-container {
            margin-top: 20px;
        }
    </style>
</head>
<body>
    <h1>Emotion Recognition from a Photo</h1>
    
    <div id="video-container">
        <video id="videoElement" autoplay></video>
        <button id="captureBtn">Capture Image and Analyze Emotion</button>
    </div>
    
    <div id="result-container">
        <h2>Analysis Result</h2>
        <img id="processedImage" src="" alt="Processed Image" style="display:none;">
        <p id="emotionText"></p>
    </div>
    
    <canvas id="canvas" style="display:none;"></canvas>

    <script>
        const videoElement = document.getElementById('videoElement');
        const captureBtn = document.getElementById('captureBtn');
        const canvas = document.getElementById('canvas');
        const context = canvas.getContext('2d');
        const processedImage = document.getElementById('processedImage');
        const emotionText = document.getElementById('emotionText');

        // Access the user's webcam
        navigator.mediaDevices.getUserMedia({ video: true, audio: false })
            .then(function(stream) {
                videoElement.srcObject = stream;
            })
            .catch(function(err) {
                console.log("An error occurred: " + err);
            });

        // Function to capture, send, and display results
        captureBtn.addEventListener('click', () => {
        // Define a new, smaller size for the canvas
        const width = 320;
        const height = videoElement.videoHeight / (videoElement.videoWidth / width);

        canvas.width = width;
        canvas.height = height;
        
        // Draw the video frame onto the resized canvas
        context.drawImage(videoElement, 0, 0, width, height);
        
        // Get the image data from the resized canvas
        const dataURL = canvas.toDataURL('image/jpeg', 0.8);
        
        // Send the smaller data to the server
        fetch('/analyze_image', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({ image: dataURL })
            })
            .then(response => response.json())
            .then(data => {
                // Display the processed image and emotion
                processedImage.src = data.processed_image;
                processedImage.style.display = 'block';
                emotionText.textContent = `Predicted Emotion: ${data.emotion}`;
            })
            .catch(error => {
                console.error('Error:', error);
            });
        });
    </script>
</body>
</html>
